export interface Speaker {
  speakerId: string;
  displayName: string;
  colorIndex: number;
}

export interface Term {
  termId: string;
  key: string;
  display: string;
  definition: string;
  aliases: string[];
}

export interface TermOccurrence {
  occurrenceId: string;
  termId: string;
  segmentId: string;
  startChar: number;
  endChar: number;
}

export interface Topic {
  topicId: string;
  title: string;
  startIndex: number; // Segment index
  endIndex: number; // Segment index
  type: 'main' | 'tangent';
  parentTopicId?: string; // For tangents
}

export interface Person {
  personId: string;
  name: string;
  affiliation?: string;
  userNotes?: string;
}

export interface Segment {
  segmentId: string;
  index: number;
  speakerId: string;
  startMs: number;
  endMs: number;
  text: string;
}

/**
 * Processing mode for chunked audio uploads.
 * - 'parallel': Chunks process independently (fast, speaker reconciliation at merge)
 * - 'sequential': Chunks wait for predecessor context (legacy, consistent speaker IDs)
 */
export type ProcessingMode = 'parallel' | 'sequential';

export interface Conversation {
  conversationId: string;
  userId: string; // Owner's Firebase UID - isolates data per user
  title: string;
  createdAt: string;
  updatedAt: string; // For sync conflict resolution and tracking
  durationMs: number;
  audioUrl?: string; // Ephemeral signed URL for audio playback (not stored in Firestore)
  audioStoragePath?: string; // Firebase Storage path for audio file
  status: 'processing' | 'needs_review' | 'complete' | 'failed' | 'aborted';
  abortRequested?: boolean;  // Set to true to request abort, Cloud Function checks this
  speakers: Record<string, Speaker>;
  segments: Segment[];
  terms: Record<string, Term>;
  termOccurrences: TermOccurrence[]; // Flat list for easy lookup
  topics: Topic[];
  people: Person[];
  // Server-side alignment status (set by Cloud Function after WhisperX processing)
  // - 'pending': Alignment not yet attempted (processing)
  // - 'aligned': WhisperX alignment succeeded
  // - 'fallback': WhisperX failed, using Gemini timestamps (may be inaccurate)
  alignmentStatus?: 'pending' | 'aligned' | 'fallback';
  alignmentError?: string; // Error message if alignment failed (for fallback status)
  // Processing mode for chunked uploads (defaults to 'parallel' for new uploads)
  processingMode?: ProcessingMode;
  // Speaker reconciliation metadata (parallel mode only)
  reconciliationConfidence?: number;
  reconciliationDetails?: ReconciliationDetails;

  // Progressive processing status (all optional for backward compatibility)
  processingProgress?: ProcessingProgress;
  processingTimeline?: ProcessingTimeline[];

  // Sync metadata (future use for Firestore sync)
  syncStatus?: 'local_only' | 'synced' | 'pending_upload' | 'conflict';
  lastSyncedAt?: string;
}

export interface PlaybackState {
  isPlaying: boolean;
  currentTimeMs: number;
  durationMs: number;
  playbackRate: number;
}

// User profile stored in Firestore users/{userId} collection
export interface UserProfile {
  userId: string;
  email: string;
  displayName?: string;
  photoURL?: string;
  isAdmin: boolean; // Admin users can access observability dashboard
  createdAt: string;
  lastLoginAt?: string;
}

// Processing step enum for granular status tracking
export enum ProcessingStep {
  PENDING = 'pending',
  UPLOADING = 'uploading',
  PRE_ANALYZING = 'pre_analyzing',
  TRANSCRIBING = 'transcribing',
  ANALYZING = 'analyzing',
  REASSIGNING = 'reassigning',
  ALIGNING = 'aligning',
  FINALIZING = 'finalizing',
  COMPLETE = 'complete',
  FAILED = 'failed'
}

// Metadata for each processing step (UI display info)
export interface StepMeta {
  label: string;
  description?: string;
  category: 'pending' | 'active' | 'success' | 'error';
}

// Real-time processing progress for user feedback
export interface ProcessingProgress {
  currentStep: ProcessingStep;
  percentComplete: number; // 0-100
  stepStartedAt?: string; // ISO timestamp
  estimatedRemainingMs?: number;
  errorMessage?: string;
  stepMeta?: StepMeta; // Optional metadata for enhanced UI feedback
}

// Timeline tracking for performance analysis
export interface ProcessingTimeline {
  stepName: ProcessingStep;
  startedAt: string; // ISO timestamp
  completedAt?: string; // ISO timestamp
  durationMs?: number;
}

// =============================================================================
// Chunked Processing Types
// =============================================================================

/**
 * Status of individual chunk processing.
 * Used to track progress and enable resumable execution.
 */
export type ChunkProcessingStatus = 'pending' | 'processing' | 'complete' | 'failed';

/**
 * Status entry for a single chunk in the processing pipeline.
 * Tracks lifecycle timestamps and any errors for resume logic.
 */
export interface ChunkStatus {
  /** Zero-indexed chunk number */
  chunkIndex: number;
  /** Current processing state */
  status: ChunkProcessingStatus;
  /** When processing started (ISO timestamp) */
  startedAt?: string;
  /** When processing completed (ISO timestamp) */
  completedAt?: string;
  /** Error message if status is 'failed' */
  error?: string;
  /** Number of retry attempts for this chunk */
  retryCount?: number;
}

/**
 * Speaker identity mapping preserved across chunk boundaries.
 * Maps pyannote speaker IDs to consistent identities.
 */
export interface SpeakerMapping {
  /** Original speaker ID from current chunk (e.g., "SPEAKER_00") */
  originalId: string;
  /** Canonical speaker ID used across all chunks */
  canonicalId: string;
  /** Inferred display name if known */
  displayName?: string;
  /** Voice signature hint for matching (future use) */
  voiceSignature?: string;
}

/**
 * Context passed between chunk processing tasks.
 * Enables diarization continuity and resumable execution.
 *
 * This is the state machine's "carry forward" data - each chunk
 * reads the previous context and emits a new one for the next chunk.
 */
export interface ChunkContext {
  /** Which chunk this context was emitted by (for validation) */
  emittedByChunkIndex: number;
  /** Speaker mappings discovered so far */
  speakerMap: SpeakerMapping[];
  /** Short summary of content processed so far (max ~512 chars, sanitized) */
  previousSummary: string;
  /** Terms extracted from previous chunks (for deduplication) */
  knownTermIds: string[];
  /** Topic IDs from previous chunks */
  knownTopicIds: string[];
  /** Person IDs from previous chunks */
  knownPersonIds: string[];
  /** Total segments processed so far (for index continuity) */
  cumulativeSegmentCount: number;
  /** Timestamp of last processed audio (ms in original) for continuity */
  lastProcessedMs: number;
}

/**
 * Firestore-stored chunking metadata with status tracking.
 * Extended from the original chunkMetadata to include context propagation.
 */
export interface ChunkingMetadata {
  /** Whether chunking was applied */
  chunkingEnabled: boolean;
  /** Total number of chunks */
  totalChunks: number;
  /** Number of chunks that completed successfully */
  completedChunks: number;
  /** Per-chunk status array */
  chunkStatuses: ChunkStatus[];
  /** Per-chunk context sequence (chunkContexts[i] = context emitted by chunk i) */
  chunkContexts: ChunkContext[];
  /** When chunking was initiated (ISO timestamp) */
  chunkedAt: string;
  /** Original audio duration (ms) */
  originalDurationMs: number;
  /** Original audio storage path */
  originalStoragePath: string;
}

/**
 * Result returned by the transcription pipeline for chunk context propagation.
 * Contains the data needed to build the next chunk's context.
 */
export interface ChunkPipelineResult {
  /** Speaker mappings discovered in this chunk (originalId â†’ canonicalId) */
  speakerMappings: SpeakerMapping[];
  /** Short summary of content processed (will be sanitized/truncated) */
  summary: string;
  /** Term IDs extracted in this chunk */
  termIds: string[];
  /** Topic IDs extracted in this chunk */
  topicIds: string[];
  /** Person IDs extracted in this chunk */
  personIds: string[];
  /** Number of segments processed in this chunk */
  segmentCount: number;
  /** Last timestamp processed in this chunk (ms) */
  lastTimestampMs: number;
}

// =============================================================================
// Speaker Reconciliation Types (Parallel Mode)
// =============================================================================

/**
 * Detailed match evidence for speaker reconciliation.
 * Provides transparency into how speakers were matched across chunks.
 */
export interface ReconciliationDetails {
  /** Number of clusters (canonical speakers) created */
  clusterCount: number;
  /** Total number of original speakers across all chunks */
  originalSpeakerCount: number;
  /** Per-cluster match evidence */
  clusters: Array<{
    canonicalId: string;
    originalIds: string[];
    confidence: number;
    displayName: string;
    matchEvidence: {
      nameMatches: number;
      topicOverlap: number;
      termOverlap: number;
    };
  }>;
}
